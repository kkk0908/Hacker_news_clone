[{"item_id": 21102586, "text": "Another great library from the author of pybind11. I was blown away (as a non CS person) that they approached GPU arrays by bypassing CUDA altogether and generating PTX on the fly, followed by JIT compiling it. It could be a trivial concept for more experienced folks here, but it did expand my feeble mind. I was even thinking about trying such an approach in Rust, which I&#x27;m learning at the moment.", "by": "mindv0rtex"}, {"item_id": 21102925, "text": "This looks pretty amazing.<p>It seems like it&#x27;s basically a library for program transformation - more or less two kinds of transformation, parallelization&#x2F;vectorization and automatic differentiation.<p>The question I would have is; suppose you have some large program which gets transformed into a system that pipes vectors from location to location, doing operations, how do you deal with issues of data&#x2F;memory divergence [1]. Basically, how to do you tune the system the data you are using stays in the cache - without consider cache, many advantages of a GPU can be lost. These messy issues tend appear whenever one engages in code generation. Purely piece vectorizations don&#x27;t have the problem but anything where you&#x27;re partially reducing and such could have the problem.<p>[1] (Best quick reference I could Google up quickly on what data divergence is) <a href=\"https:&#x2F;&#x2F;etd.auburn.edu&#x2F;handle&#x2F;10415&#x2F;4688\" rel=\"nofollow\">https:&#x2F;&#x2F;etd.auburn.edu&#x2F;handle&#x2F;10415&#x2F;4688</a>", "by": "joe_the_user"}]